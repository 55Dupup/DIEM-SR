#### general settings
name: try_channel4_trainall_pre_justSR
use_tb_logger: false
model: DegSRModel
scale: 4
gpu_ids: [0]
metrics: [best_psnr, best_ssim, lpips]

#### datasets
datasets:
  train:
    name: myDataset_train
    mode: UnPairedDataset
    data_type: lmdb
    color: RGB
    ratios: [200, 200]

    dataroot_tgt: ../../../data_samples/trainData_HR.lmdb
    dataroot_src: ../../../data_samples/trainData_LR.lmdb

    use_shuffle: true
    workers_per_gpu: 8  # per GPU
    imgs_per_gpu: 16
    tgt_size: 192
    src_size: 48
    use_flip: true
    use_rot: true

  val:
    name: myDataset_val
    mode: PairedDataset
    data_type: lmdb
    color: RGB
    dataroot_tgt: ../../../data_samples/GT.lmdb
    dataroot_src: ../../../data_samples/LR_twitterX4.lmdb

#### network structures
networks:
  netDeg:
    which_network: DegModel
    setting:
      scale: 4
      nc_img: 3
      kernel_opt: 
        mix: false
        spatial: false
        nc: 3 #3
        nf: 64
        nb: 32
        head_k: 1
        body_k: 1
        ksize: 21
        zero_init: true
      noise_opt: 
        mix: true #false
        nc: 3
        nf: 64
        nb: 16
        head_k: 3
        body_k: 3
        dim: 3
        zero_init: true
    pretrain: 
      path: ~
      strict_load: true
  netSR:
    which_network: EDSR
    setting:
      nf: 64
      nb: 16
      res_scale: 1
      upscale: 4
    pretrain: 
      path: ../../../checkpoints/edsr_baseline_x4-new.pt
      strict_load: true
  netD1:
    which_network: PatchGANDiscriminator
    setting:
      in_c: 3
      nf: 64
      nb: 3
      stride: 1
    pretrain: 
      path: ~
      strict_load: true
#### training settings: learning rate scheme, loss
train:
  resume_state: ~
  D_ratio: 5
  max_grad_norm: 50
  buffer_size: 0
  
  optim_sr: true
  optim_deg: false
  
  losses:
  
    lr_adv:
      type: GANLoss
      gan_type: lsgan
      real_label_val: 1.0
      fake_label_val: 0.0
      weight: !!float 1.0
    
    noise_mean:
      type: MSELoss
      weight: 100.0
    sr_pix_sr: 
      type: L1Loss
      weight: 1.0
    

  optimizers:
    netDeg:
      type: Adam
      lr: !!float 1e-5
    netD1:
      type: Adam
      lr: !!float 1e-5
    netSR:
      type: Adam
      lr: !!float 2e-5
#      lr: !!float 2e-7     

   
  niter: 200000
  warmup_iter: -1  # no warm up

  schedulers:
    default:
      type: MultiStepRestartLR
      milestones: [50000, 100000, 150000]
      gamma: 0.5

  manual_seed: 0
  val_freq: !!float 5e3

#### logger
logger:
  print_freq: 100
  save_checkpoint_freq: !!float 5e3
